{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sklearn_crfsuite\n",
    "import collections\n",
    "import glob\n",
    "from deepmerge import always_merger\n",
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\ML\\\\IBS'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('d:/Projects/IT/IBS/ibs_web')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Projects\\\\IT\\\\IBS\\\\ibs_web'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from parsers.CrfPredictor import CrfPredictor\n",
    "from parsers.DocxParser import DocxParser\n",
    "from parsers.PullentiParser import PullentiParser\n",
    "from parsers.FeaturesLabelsIterator import FeaturesLabelsIterator\n",
    "from extractors.IbsAttrExtractor import IbsAttrExtractor\n",
    "from utils import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлекаем файкты как они есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: 602\n"
     ]
    }
   ],
   "source": [
    "input_path = 'd:/Projects/IT/IBS/data/input-599'\n",
    "output_file = 'd:/Projects/IT/IBS/data/facts_export/facts-599.xlsx'\n",
    "docx_files = glob.glob(os.path.join(input_path, '**', '*.docx'), recursive=True)\n",
    "print('Files: {}'.format(len(docx_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docxParser = DocxParser()\n",
    "datasets = {}\n",
    "\n",
    "for docx_file in docx_files:\n",
    "    docxParser.parse(docx_file)\n",
    "#     try:\n",
    "    true_facts = docxParser.get_fact_values()\n",
    "#     except Exception as e:\n",
    "#         print(docx_file)\n",
    "    rel_path = docx_file[len(input_path):]\n",
    "    for true_fact in true_facts:\n",
    "        for tag, value in true_fact.items():\n",
    "            if tag not in datasets:\n",
    "                datasets[tag] = pd.DataFrame()\n",
    "            datasets[tag] = datasets[tag].append([{\n",
    "                    'file': rel_path,\n",
    "                    'value': value,\n",
    "                }], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(output_file, engine='xlsxwriter')\n",
    "\n",
    "for tag in datasets.keys():\n",
    "    # Write each dataframe to a different worksheet.\n",
    "    datasets[tag].to_excel(writer, sheet_name=tag)\n",
    "    \n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция извлечения фактов модифицированная чтобы доставать именованные сущности pullenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fact_values(pullentiParser, labels, marginals, scan_text, scan_tables):\n",
    "    fact_values = {}\n",
    "\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "    label = None\n",
    "    label_idx = 0\n",
    "    prob = None\n",
    "\n",
    "    if scan_text:\n",
    "        # process text\n",
    "        for word_idx, word in enumerate(pullentiParser.src_text):\n",
    "            # if found start tag (B-)\n",
    "            if labels[label_idx].startswith('B-'):\n",
    "                start_idx = word_idx\n",
    "                label = labels[label_idx][2:]\n",
    "                if marginals is not None:\n",
    "                    prob = marginals(labels[label_idx], label_idx)\n",
    "                label_idx += 1\n",
    "                continue\n",
    "\n",
    "            # found end tag\n",
    "            if label is not None and label != labels[label_idx]:\n",
    "                end_idx = word_idx\n",
    "                # extract fact value\n",
    "                words = []\n",
    "                for i in range(start_idx, end_idx):\n",
    "                    if '(' in pullentiParser.morphs[i] and ')' in pullentiParser.morphs[i]:\n",
    "                        words.append(pullentiParser.morphs[i])\n",
    "                    else:\n",
    "                        words.append(pullentiParser.src_text[i])\n",
    "                value = ' '.join(words)\n",
    "                \n",
    "#                 value = ' '.join(pullentiParser.src_text[start_idx:end_idx])\n",
    "                FeaturesLabelsIterator.append_fact_value(fact_values, label, value, prob)\n",
    "\n",
    "                start_idx = None\n",
    "                end_idx = None\n",
    "                label = None\n",
    "\n",
    "            label_idx += 1\n",
    "\n",
    "        # достигли конца текста, а окончание тэга не обработано\n",
    "        if label is not None:\n",
    "            value = ' '.join(pullentiParser.src_text[start_idx:])\n",
    "            FeaturesLabelsIterator.append_fact_value(fact_values, label, value, prob)\n",
    "\n",
    "    if scan_tables:\n",
    "        # process tables\n",
    "        for tbl_idx, tbl_src_text in enumerate(pullentiParser.tables_src_text):\n",
    "            for row_idx, row_src_text in enumerate(tbl_src_text):\n",
    "                for cell_idx, cell_src_text in enumerate(row_src_text):\n",
    "                    if cell_src_text is not None and len(cell_src_text) > 0:\n",
    "                        # pullentiParser.tables_labels[tbl_idx][row_idx][cell_idx] = []\n",
    "                        start_idx = None\n",
    "                        end_idx = None\n",
    "                        label = None\n",
    "                        prob = None\n",
    "\n",
    "                        for word_idx, word in enumerate(cell_src_text):\n",
    "\n",
    "                            # update table label\n",
    "                            # pullentiParser.tables_labels[tbl_idx][row_idx][cell_idx].append(labels[label_idx])\n",
    "\n",
    "                            # found end tag\n",
    "                            if label is not None and label != labels[label_idx]:\n",
    "                                end_idx = word_idx\n",
    "                                words = []\n",
    "                                morphs = pullentiParser.tables_morphs[tbl_idx][row_idx][cell_idx]\n",
    "                                for i in range(start_idx, end_idx):\n",
    "                                    if '(' in morphs[i] and ')' in morphs[i]:\n",
    "                                        words.append(morphs[i])\n",
    "                                    else:\n",
    "                                        words.append(cell_src_text[i])\n",
    "                                value = ' '.join(words)\n",
    "#                                 value = ' '.join(cell_src_text[start_idx:end_idx])\n",
    "                                FeaturesLabelsIterator.append_fact_value(fact_values, label, value, prob)\n",
    "\n",
    "                                start_idx = None\n",
    "                                end_idx = None\n",
    "                                label = None\n",
    "\n",
    "                            # if found start tag (B-)\n",
    "                            if labels[label_idx].startswith('B-'):\n",
    "                                start_idx = word_idx\n",
    "                                label = labels[label_idx][2:]\n",
    "                                if marginals is not None:\n",
    "                                    prob = marginals(labels[label_idx], label_idx)\n",
    "                                label_idx += 1\n",
    "                                continue\n",
    "\n",
    "                            label_idx += 1\n",
    "\n",
    "                        # достигли конца ячейки, а окончание тэга не обработано\n",
    "                        if label is not None:\n",
    "                            words = []\n",
    "                            morphs = pullentiParser.tables_morphs[tbl_idx][row_idx][cell_idx]\n",
    "                            for i in range(start_idx, len(cell_src_text)):\n",
    "                                if '(' in morphs[i] and ')' in morphs[i]:\n",
    "                                    words.append(morphs[i])\n",
    "                                else:\n",
    "                                    words.append(cell_src_text[i])\n",
    "                            value = ' '.join(words)\n",
    "#                             value = ' '.join(cell_src_text[start_idx:])\n",
    "                            FeaturesLabelsIterator.append_fact_value(fact_values, label, value, prob)\n",
    "\n",
    "    return fact_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работаем с файлами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: 599\n"
     ]
    }
   ],
   "source": [
    "input_path = 'd:/Projects/IT/IBS/data/pickle-input-data-599'\n",
    "pickle_files = glob.glob(os.path.join(input_path, '**', '*.pickle'), recursive=True)\n",
    "print('Files: {}'.format(len(pickle_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10de8166494c42e384de36b7abfe2217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O1': [{'value': 'Администрации (geo)', 'prob': None}], 'D': [{'value': '(date)', 'prob': None}], 'R': [{'value': '(number)', 'prob': None}], 'O2': [{'value': 'отдел по делам молодежи и спорту Администрации (geo)', 'prob': None}], 'ND1': [{'value': 'муниципальная программа « Развитие физической культуры и спорта в (geo) » на (daterange)', 'prob': None}], 'G': [{'value': 'создание условий для укрепления здоровья населения Зонального района путем развития инфраструктуры спорта и приобщения различных слоев населения к регулярным занятиям физической культурой и спортом', 'prob': None}], 'T': [{'value': 'создание правовых , экономических , социальных и организационных условий для развития массовой физической культуры и спорта в (geo) ;', 'prob': None}, {'value': 'создание оптимальных условий для развития в (geo) детско - юношеского и массового спорта ;', 'prob': None}, {'value': 'формирование у населения навыков здорового образа жизни , воспитание осознанной потребности в физическом совершенствовании ;', 'prob': None}, {'value': 'сохранение , развитие и эффективное использование материально - спортивной базы на территории муниципального образования (geo)', 'prob': None}], 'P': [{'value': '(daterange)', 'prob': None}], 'H': [{'value': 'Наименование индикатора ( показателя )', 'prob': None}, {'value': 'Наименование индикатора ( показателя )', 'prob': None}, {'value': 'Наименование индикатора ( показателя )', 'prob': None}], 'K': [{'value': 'Уровень обеспеченности населения Зонального района спортивными сооружениями , исходя из единовременной пропускной способности объектов спорта', 'prob': None}, {'value': 'Удельный вес населения Зонального района , систематически занимающегося физической культурой и спортом', 'prob': None}, {'value': 'Количество занимающихся физической культурой и спортом', 'prob': None}, {'value': 'Количество проведенных ( и участие ) соревнований , турниров', 'prob': None}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pullentiParser = PullentiParser()\n",
    "\n",
    "ks = []\n",
    "goals = []\n",
    "tasks = []\n",
    "\n",
    "for pickle_file in tqdm(pickle_files[:1]):\n",
    "    pullentiParser.load_from_pickle_file(pickle_file)\n",
    "#     true_facts = pullentiParser._get_true_facts(pullentiParser)\n",
    "    facts = get_fact_values(pullentiParser, pullentiParser.labels + list(flatten(pullentiParser.tables_labels)), None, True, True)\n",
    "    print(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fact_text(facts, tag):\n",
    "    \"\"\"ИТзвлечение текста фактов\"\"\"\n",
    "    result = []\n",
    "    if tag in facts:\n",
    "        result = [fv['value'] for fv in facts[tag]]\n",
    "        result = list(set(result))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471c0097dc2a4e8cbe5a7acdb8f30a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=599), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pullentiParser = PullentiParser()\n",
    "\n",
    "ks = []\n",
    "goals = []\n",
    "tasks = []\n",
    "\n",
    "for pickle_file in tqdm(pickle_files):\n",
    "    pullentiParser.load_from_pickle_file(pickle_file)\n",
    "    facts = get_fact_values(pullentiParser, pullentiParser.labels + list(flatten(pullentiParser.tables_labels)), None, True, True)\n",
    "    \n",
    "    ks.extend(get_fact_text(facts, 'K'))\n",
    "    goals.extend(get_fact_text(facts, 'G'))\n",
    "    tasks.extend(get_fact_text(facts, 'T'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### пишем в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = 'd:/Projects/IT/IBS/data/facts_export'\n",
    "\n",
    "with io.open(os.path.join(out_path, 'K.txt'), 'w', encoding='utf8') as f:\n",
    "    f.write(\"\\n\".join(ks))\n",
    "    \n",
    "with io.open(os.path.join(out_path, 'G.txt'), 'w', encoding='utf8') as f:\n",
    "    f.write(\"\\n\".join(goals))\n",
    "    \n",
    "with io.open(os.path.join(out_path, 'T.txt'), 'w', encoding='utf8') as f:\n",
    "    f.write(\"\\n\".join(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
